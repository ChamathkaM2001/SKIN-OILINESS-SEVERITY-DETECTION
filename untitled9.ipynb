{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1z1Bd30wdNRIL8nJWYNmxSi3GrUQGv9mD",
      "authorship_tag": "ABX9TyNfMH8Xb75N3SX260mz/UVW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChamathkaM2001/SKIN-OILINESS-SEVERITY-DETECTION/blob/main/untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFrSKybSKtOr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "IMAGE_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n"
      ],
      "metadata": {
        "id": "plOncsLwNR7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to train, test, and validation data\n",
        "train_dir = '/content/drive/MyDrive/test'\n",
        "test_dir = '/content/drive/MyDrive/test'\n",
        "validation_dir = '/content/drive/MyDrive/valid'\n"
      ],
      "metadata": {
        "id": "HtC5_ggzupxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create image data generators with data augmentation for train and validation sets\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "jhZ2fcB7vM3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "JwuxGsCGvc09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09tVBVmbvgkp",
        "outputId": "8343cd1b-965c-4a9f-a234-4f99d6925afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 144 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IbVBPM10pYl",
        "outputId": "5190ea45-1229-4dd8-96c3-5f7875593efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 278 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')  # Assuming there are 4 classes: oily 1, oily 2, oily 3, oily 4\n",
        "])"
      ],
      "metadata": {
        "id": "WAAlnZdQ0q9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "l-iwELSj0zYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctagDII008fQ",
        "outputId": "9e3d1f34-afe1-4470-ae8a-71c03cd466d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 155s 47s/step - loss: 1.4151 - accuracy: 0.2411 - val_loss: 1.4019 - val_accuracy: 0.2148\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 6s 2s/step - loss: 1.3841 - accuracy: 0.1875 - val_loss: 1.3748 - val_accuracy: 0.3008\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 6s 2s/step - loss: 1.3785 - accuracy: 0.2768 - val_loss: 1.3592 - val_accuracy: 0.3008\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3579 - accuracy: 0.3214 - val_loss: 1.3447 - val_accuracy: 0.3086\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 6s 2s/step - loss: 1.3450 - accuracy: 0.2054 - val_loss: 1.3545 - val_accuracy: 0.2891\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3529 - accuracy: 0.3214 - val_loss: 1.3321 - val_accuracy: 0.3555\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3497 - accuracy: 0.2768 - val_loss: 1.3441 - val_accuracy: 0.3555\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3320 - accuracy: 0.3750 - val_loss: 1.3344 - val_accuracy: 0.3672\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3316 - accuracy: 0.3304 - val_loss: 1.3412 - val_accuracy: 0.3555\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3295 - accuracy: 0.3359 - val_loss: 1.3353 - val_accuracy: 0.3398\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3195 - accuracy: 0.3036 - val_loss: 1.3268 - val_accuracy: 0.3438\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3035 - accuracy: 0.3482 - val_loss: 1.3459 - val_accuracy: 0.3398\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.3419 - accuracy: 0.2857 - val_loss: 1.3174 - val_accuracy: 0.3594\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 6s 2s/step - loss: 1.2987 - accuracy: 0.3482 - val_loss: 1.3424 - val_accuracy: 0.3320\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 6s 2s/step - loss: 1.3064 - accuracy: 0.3929 - val_loss: 1.3625 - val_accuracy: 0.3555\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.2826 - accuracy: 0.3125 - val_loss: 1.3638 - val_accuracy: 0.3086\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.2845 - accuracy: 0.3482 - val_loss: 1.3711 - val_accuracy: 0.3398\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.2727 - accuracy: 0.3214 - val_loss: 1.3685 - val_accuracy: 0.3164\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 7s 2s/step - loss: 1.2786 - accuracy: 0.3438 - val_loss: 1.3671 - val_accuracy: 0.3398\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 6s 2s/step - loss: 1.2973 - accuracy: 0.3393 - val_loss: 1.3774 - val_accuracy: 0.3281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "bed6Rh_V09m7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18387f7c-29f9-42ed-827f-68c9e38bee23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 144 images belonging to 4 classes.\n"
          ]
        }
      ]
    }
  ]
}